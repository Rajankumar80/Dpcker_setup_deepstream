import gi
gi.require_version("Gst", "1.0")
from gi.repository import Gst
import cv2
import numpy as np
import threading
import queue
import time
import signal
import sys
from abc import ABC, abstractmethod
from openvino import Core, AsyncInferQueue

CONFIG = {
    "model": {
        "path": "/home/shekar/video_pipeline/yolov8n_openvino_model/yolov8n.xml",
        "device": "CPU"
    },
    "thresholds": {
        "conf": 0.35,
        "nms": 0.45
    },
    "input_size": 640,
    "streams": [
        "rtsp://10.64.36.13:554/rtsp/streaming?channel=01&subtype=1",
        "rtsp://10.64.36.14:554/rtsp/streaming?channel=01&subtype=1",
    ]
}

CLASSES = ["person","bicycle","car","motorcycle","airplane","bus","train","truck","boat",
"traffic light","fire hydrant","stop sign","parking meter","bench","bird","cat","dog",
"horse","sheep","cow","elephant","bear","zebra","giraffe","backpack","umbrella",
"handbag","tie","suitcase","frisbee","skis","snowboard","sports ball","kite",
"baseball bat","baseball glove","skateboard","surfboard","tennis racket","bottle",
"wine glass","cup","fork","knife","spoon","bowl","banana","apple","sandwich",
"orange","broccoli","carrot","hot dog","pizza","donut","cake","chair","couch",
"potted plant","bed","dining table","toilet","tv","laptop","mouse","remote",
"keyboard","cell phone","microwave","oven","toaster","sink","refrigerator","book",
"clock","vase","scissors","teddy bear","hair drier","toothbrush"]

Gst.init(None)

class YOLOv8Model:
    def __init__(self, cfg):
        try:
            self.input_size = CONFIG["input_size"]
            self.conf = CONFIG["thresholds"]["conf"]
            self.nms = CONFIG["thresholds"]["nms"]
            self.core = Core()
            model = self.core.read_model(cfg["path"])
            self.compiled = self.core.compile_model(model, cfg["device"])
            self.infer_queue = AsyncInferQueue(self.compiled, jobs=4)
        except Exception as e:
            print(f"Model Init Error: {e}")
            sys.exit(1)

    def preprocess(self, frame):
        try:
            img = cv2.resize(frame, (self.input_size, self.input_size))
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            blob = img.transpose(2,0,1)[None].astype(np.float32)
            blob /= 255.0
            return blob
        except:
            return None

    def postprocess(self, infer_result, shape):
        try:
            output = infer_result.get_output_tensor().data
            output = np.squeeze(output).T
            h, w = shape
            scores_max = np.max(output[:, 4:], axis=1)
            mask = scores_max > self.conf
            output = output[mask]
            boxes, scores, class_ids = [], [], []
            sx, sy = w / self.input_size, h / self.input_size
            for row in output:
                probs = row[4:]
                cid = np.argmax(probs)
                score = probs[cid]
                boxes.append([int((row[0]-row[2]/2)*sx), int((row[1]-row[3]/2)*sy), int(row[2]*sx), int(row[3]*sy)])
                scores.append(float(score))
                class_ids.append(cid)
            if not boxes: return []
            idx = cv2.dnn.NMSBoxes(boxes, scores, self.conf, self.nms)
            return [(boxes[i], scores[i], class_ids[i]) for i in idx.flatten()]
        except:
            return []

class BusinessLogic:
    def process(self, detections):
        events = []
        for _, _, cid in detections:
            if CLASSES[cid] == "person":
                events.append("PERSON_DETECTED")
        return events

class OutputHandler:
    def draw(self, frame, detections):
        for box, score, cid in detections:
            x,y,w,h = box
            label = f"{CLASSES[cid]} {score:.2f}"
            color = (0,255,0) if CLASSES[cid]=="person" else (255,128,0)
            cv2.rectangle(frame,(x,y),(x+w,y+h),color,2)
            cv2.putText(frame,label,(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255, 255, 0),1)

class CameraStream:
    def __init__(self, cam_id, url, model, logic, output, display_queue):
        self.cam_id, self.url, self.model, self.logic, self.output, self.display_queue = cam_id, url, model, logic, output, display_queue
        self.frame_queue = queue.Queue(maxsize=2)
        self.running = True
        self.pipeline = None
        threading.Thread(target=self.capture_loop, daemon=True).start()
        threading.Thread(target=self.inference_loop, daemon=True).start()

    def build_pipeline(self):
        return Gst.parse_launch(f'rtspsrc location="{self.url}" protocols=tcp latency=200 ! rtph265depay ! h265parse ! avdec_h265 ! videoconvert ! videoscale ! video/x-raw,width=640,height=360,format=BGR ! appsink name=sink emit-signals=true sync=false max-buffers=1 drop=true')

    def on_sample(self, sink):
        try:
            sample = sink.emit("pull-sample")
            if not sample: return Gst.FlowReturn.OK
            buf = sample.get_buffer()
            res, map_info = buf.map(Gst.MapFlags.READ)
            if res:
                try:
                    if not self.frame_queue.full() and self.running:
                        frame = np.frombuffer(map_info.data, dtype=np.uint8).reshape((360,640,3)).copy()
                        self.frame_queue.put_nowait(frame)
                finally:
                    buf.unmap(map_info)
            return Gst.FlowReturn.OK
        except:
            return Gst.FlowReturn.OK

    def capture_loop(self):
        while self.running:
            try:
                self.pipeline = self.build_pipeline()
                sink = self.pipeline.get_by_name("sink")
                sink.connect("new-sample", self.on_sample)
                self.pipeline.set_state(Gst.State.PLAYING)
                bus = self.pipeline.get_bus()
                while self.running:
                    msg = bus.timed_pop(Gst.SECOND)
                    if msg and msg.type == Gst.MessageType.ERROR: break
                self.pipeline.set_state(Gst.State.NULL)
            except: pass
            if not self.running: break
            time.sleep(1)

    def inference_loop(self):
        def callback(infer_request, user_data):
            try:
                if not self.running: return
                frame, cam_id = user_data
                detections = self.model.postprocess(infer_request, frame.shape[:2])
                _ = self.logic.process(detections)
                self.output.draw(frame, detections)
                if not self.display_queue.full(): self.display_queue.put_nowait((cam_id, frame))
            except: pass

        self.model.infer_queue.set_callback(callback)
        while self.running:
            try:
                frame = self.frame_queue.get(timeout=1)
                blob = self.model.preprocess(frame)
                if blob is not None: self.model.infer_queue.start_async(blob, (frame, self.cam_id))
            except: continue

class SurveillanceSystem:
    def __init__(self):
        urls = CONFIG["streams"]
        num_cameras = len(urls)
        self.model, self.logic, self.output = YOLOv8Model(CONFIG["model"]), BusinessLogic(), OutputHandler()
        self.display_queue = queue.Queue(maxsize=num_cameras * 2)
        self.streams = [CameraStream(i,url,self.model,self.logic,self.output,self.display_queue) for i,url in enumerate(urls)]
        self.latest_frames = {i:None for i in range(num_cameras)}
        
        signal.signal(signal.SIGINT, self.shutdown_handler)
        signal.signal(signal.SIGTERM, self.shutdown_handler)
        
        self.display_loop()

    def display_loop(self):
        cv2.namedWindow("Surveillance", cv2.WINDOW_AUTOSIZE)

        while True:
            try:
                while not self.display_queue.empty():
                    cid, frame = self.display_queue.get_nowait()
                    self.latest_frames[cid] = frame

                valid_frames = [
                    self.latest_frames[i]
                    for i in sorted(self.latest_frames.keys())
                    if self.latest_frames[i] is not None
                ]

                if valid_frames:
                    n = len(valid_frames)

                    if n == 1:
                        grid = valid_frames[0]

                    elif n == 2:
                        grid = np.hstack(valid_frames)

                    else:
                        rows = []
                        for i in range(0, n, 2):
                            row_frames = valid_frames[i:i+2]

                            if len(row_frames) == 1:
                                h, w, c = row_frames[0].shape
                                blank = np.zeros((h, w, c), dtype=np.uint8)
                                row = np.hstack([row_frames[0], blank])
                            else:
                                row = np.hstack(row_frames)

                            rows.append(row)

                        grid = np.vstack(rows)

                    cv2.imshow("Surveillance", grid)

                key = cv2.waitKey(1) & 0xFF
                if key == ord('q') or cv2.getWindowProperty("Surveillance", cv2.WND_PROP_VISIBLE) < 1:
                    break

            except:
                break

        self.shutdown_handler()


    def shutdown_handler(self, *args):
        print("\n[INFO] Closing system safely...")
        for s in self.streams:
            s.running = False
            if s.pipeline:
                s.pipeline.set_state(Gst.State.NULL)
        
        cv2.destroyAllWindows()
        # Ensure the process dies immediately to release OS window resources
        time.sleep(0.5)
        print("[INFO] Cleanup complete. Exiting.")
        sys.exit(0)

if __name__ == "__main__":
    SurveillanceSystem()
 
